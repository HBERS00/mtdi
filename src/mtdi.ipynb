{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c59b86f",
   "metadata": {},
   "source": [
    "# Fake news detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c6d2f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eb4445",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900ac3b",
   "metadata": {},
   "source": [
    "Importiamo il dataset di fake news, questo dataset è composto da oltre 70 mila articoli ma per questo esperimento ne utilizziamo solamente 15 mila per ottimizzare i tempi e risparmiare risorse. \n",
    "\n",
    "Il dataset contiene un campo text contentente il testo dell'articolo e una label con i seguenti valori:\n",
    "- 0: fake\n",
    "- 1: real\n",
    "\n",
    "Il dataset è disponibile a [questo link](https://drive.google.com/file/d/1dLMKyEB3JcP-BP2F2OvqlwS2SD6UOQ8x/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe15a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('WELFake_Dataset.csv')[:15000]\n",
    "\n",
    "# Copio la colonna text per preprocessing\n",
    "df['original_text'] = df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a162316",
   "metadata": {},
   "source": [
    "Rimuovo gli articoli più corti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22386678",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_wc'] = df['text'].apply(lambda x:len(str(x).split()))\n",
    "df = df[df['text_wc'] > 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259654b",
   "metadata": {},
   "source": [
    "Mantengo solo le colonne utili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30d040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\n",
    "    'label',\n",
    "    'text',\n",
    "    'original_text'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6682984f",
   "metadata": {},
   "source": [
    "Rimuovo gli NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b08e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['label'].notna()]\n",
    "df = df[df['text'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce5f384",
   "metadata": {},
   "source": [
    "Applica lemmatizzazione, rimuove punteggiatura, stopwords, valute, numeri, tabulazioni e like num (numeri romani o in forma testuale) Usare modelli large o transformer per migliorare risultato: https://spacy.io/models/en\n",
    "\n",
    "Per il preprocessing usiamo il modello large di spacy *it_core_news_lg* che, nonostante sia pre-trainato su news è perfetto per task come lemmatization e punctuation removal\n",
    "\n",
    "Swifter usato per migliorare le prestazioni di DataFrame.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "325a5c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 12:07:04.523048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-10 12:07:04.578962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-10 12:07:04.579369: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:967] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8daf22409843fc8ac6ab327a944ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/14593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "import swifter\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "df['text'] = df.original_text.swifter.apply(lambda text: \" \".join([token.lemma_ for token in nlp(text) if \n",
    "                                             not token.is_punct \n",
    "                                             and not token.is_currency\n",
    "                                             and not token.is_digit\n",
    "                                             and not token.is_space\n",
    "                                             and not token.is_stop\n",
    "                                             and not token.like_num\n",
    "                                             ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b0b79",
   "metadata": {},
   "source": [
    "Salviamo eventualmente il dataset processato in modo da non dover ripetere tutto il processo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7930723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_fnews_15k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0946c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_fnews_15k.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9356643d",
   "metadata": {},
   "source": [
    "### Statistiche sul dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b991c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>comment expect Barack Obama member FYF911 FukY...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>demonstrator gather night exercise constitutio...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>dozen politically active pastor come private d...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>rs-28 Sarmat missile dub Satan replace SS-18 f...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>s time sue Southern Poverty Law Center!On Tues...</td>\n",
       "      <td>All we can say on this one is it s about time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>owner Ringling Bar locate south White Sulphur ...</td>\n",
       "      <td>The owner of the Ringling Bar, located south o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>file Sept. file photo marker welcome commuter ...</td>\n",
       "      <td>FILE – In this Sept. 15, 2005 file photo, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>punchable alt right Nazi internet get thorough...</td>\n",
       "      <td>The most punchable Alt-Right Nazi on the inter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>BRUSSELS Reuters british Prime Minister Theres...</td>\n",
       "      <td>BRUSSELS (Reuters) - British Prime Minister Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON Reuters Charles Schumer Democrat U....</td>\n",
       "      <td>WASHINGTON (Reuters) - Charles Schumer, the to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  label                                               text  \\\n",
       "0           0      1  comment expect Barack Obama member FYF911 FukY...   \n",
       "1           2      1  demonstrator gather night exercise constitutio...   \n",
       "2           3      0  dozen politically active pastor come private d...   \n",
       "3           4      1  rs-28 Sarmat missile dub Satan replace SS-18 f...   \n",
       "4           5      1  s time sue Southern Poverty Law Center!On Tues...   \n",
       "5           8      1  owner Ringling Bar locate south White Sulphur ...   \n",
       "6           9      1  file Sept. file photo marker welcome commuter ...   \n",
       "7          10      1  punchable alt right Nazi internet get thorough...   \n",
       "8          11      0  BRUSSELS Reuters british Prime Minister Theres...   \n",
       "9          12      0  WASHINGTON Reuters Charles Schumer Democrat U....   \n",
       "\n",
       "                                       original_text  \n",
       "0  No comment is expected from Barack Obama Membe...  \n",
       "1   Now, most of the demonstrators gathered last ...  \n",
       "2  A dozen politically active pastors came here f...  \n",
       "3  The RS-28 Sarmat missile, dubbed Satan 2, will...  \n",
       "4  All we can say on this one is it s about time ...  \n",
       "5  The owner of the Ringling Bar, located south o...  \n",
       "6  FILE – In this Sept. 15, 2005 file photo, the ...  \n",
       "7  The most punchable Alt-Right Nazi on the inter...  \n",
       "8  BRUSSELS (Reuters) - British Prime Minister Th...  \n",
       "9  WASHINGTON (Reuters) - Charles Schumer, the to...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31adc9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14593 entries, 0 to 14592\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     14593 non-null  int64 \n",
      " 1   label          14593 non-null  int64 \n",
      " 2   text           14593 non-null  object\n",
      " 3   original_text  14593 non-null  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 456.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7ef3aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7497\n",
       "0    7096\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c648120",
   "metadata": {},
   "source": [
    "## Preparazione dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e63a92",
   "metadata": {},
   "source": [
    "Converte il testo in sequenze di interi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ac1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(df['text'].tolist())\n",
    "sequences = tokenizer.texts_to_sequences(df['text'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa6837",
   "metadata": {},
   "source": [
    "Setto parametri per embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4de83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max([len(seq) for seq in sequences])\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d72f8a",
   "metadata": {},
   "source": [
    "Aggiungo padding alla fine in modo che tutte le sequenze siano di uguale lunghezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ffec4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post', maxlen=max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f3acc",
   "metadata": {},
   "source": [
    "Splitto il dataset in train, test e validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e872d043",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, df.label, test_size=0.2)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b39217",
   "metadata": {},
   "source": [
    "## Creazione modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23525c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(layers.Embedding(input_dim=vocab_size, output_dim=100, input_length=max_length))\n",
    "\n",
    "# Convolutional layer: 128 filters, kernel_size = 5\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "\n",
    "# Max pooling layer per ridurre overfitting\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "\n",
    "# Dropout layer per ridurre overfitting\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "# Flatten layer per ridurre overfitting\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add a dense layer with 32 units and a relu activation function\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "# Add an output layer with a sigmoid activation function\n",
    "model.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0ae6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e886290c",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16f682a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 12:46:04.026340: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 795203472 exceeds 10% of free system memory.\n",
      "2023-01-10 12:46:07.692287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-01-10 12:46:09.055097: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.49GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-01-10 12:46:09.055184: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.49GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-01-10 12:46:10.417247: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x250d6590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-01-10 12:46:10.417302: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2023-01-10 12:46:10.432340: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-01-10 12:46:10.635878: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 54s 320ms/step - loss: 0.4157 - accuracy: 0.7972 - val_loss: 0.1848 - val_accuracy: 0.9239\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-10 12:47:00.027952: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-01-10 12:47:00.030964: W tensorflow/tsl/framework/bfc_allocator.cc:290] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 48s 317ms/step - loss: 0.1330 - accuracy: 0.9543 - val_loss: 0.1139 - val_accuracy: 0.9558\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 47s 313ms/step - loss: 0.0437 - accuracy: 0.9875 - val_loss: 0.1057 - val_accuracy: 0.9600\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 48s 323ms/step - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.1172 - val_accuracy: 0.9586\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 49s 324ms/step - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.1192 - val_accuracy: 0.9581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2f9bde910>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f752a",
   "metadata": {},
   "source": [
    "## Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0706982d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 4s 43ms/step - loss: 0.1307 - accuracy: 0.9555\n",
      "Test accuracy: 0.9554641842842102\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8a848a",
   "metadata": {},
   "source": [
    "## Classificazione di nuove notizie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc662f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'Luigi, Italian Politician, Turns into Giant Tomato \\\n",
    "In a bizarre turn of events, local Italian politician Luigi has transformed into a giant tomato. \\\n",
    "Eyewitnesses reported that during a heated debate in the town hall, Luigi suddenly began to grow and change color, \\\n",
    "until he was a fully ripe tomato, standing at least 15 feet tall. \\\n",
    "Despite his new form, Luigi is said to be in good spirits and continues to conduct official business as normal, \\\n",
    "holding meetings and signing documents with his newly formed tomato vines. His constituents are in shock but also delight, \\\n",
    "they have never seen something like this before.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41715ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "[ FAKE ]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import swifter\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "sample_text = \" \".join([token.lemma_ for token in nlp(sample_text) if \n",
    "                                             not token.is_punct \n",
    "                                             and not token.is_currency\n",
    "                                             and not token.is_digit\n",
    "                                             and not token.is_space\n",
    "                                             and not token.is_stop\n",
    "                                             and not token.like_num\n",
    "                                             ])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences([sample_text])\n",
    "padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, padding='post', maxlen=max_length)\n",
    "\n",
    "predictions = model.predict(padded_sequences)\n",
    "prediction_npa = np.asarray(predictions[0])\n",
    "predicted_class = np.argmax(prediction_npa)\n",
    "\n",
    "if predicted_class == 0:\n",
    "    print('[ FAKE ]')\n",
    "else:\n",
    "    print('[ REAL ]')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
